{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# load up our text\n",
    "zhuangzi = open('../data/zhuangzi.txt', 'r').read().lower()\n",
    "mencius = open('../data/mencius.txt', 'r').read().lower()\n",
    "confucius = open('../data/confucius.txt', 'r').read().lower()\n",
    "\n",
    "text = '\\n'.join([zhuangzi, mencius, confucius])\n",
    "\n",
    "\n",
    "# extract all (unique) characters\n",
    "# these are our \"categories\" or \"labels\"\n",
    "chars = list(set(text))\n",
    "\n",
    "# set a fixed vector size\n",
    "# so we look at specific windows of characters\n",
    "max_len = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define our RNN. Keras makes this trivial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(max_len, len(chars))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're framing our task as a classification task. Given a sequence of characters, we want to predict the next character. We equate each character with some label or category (e.g. \"a\" is 0, \"b\" is 1, etc).\n",
    "\n",
    "We use the softmax activation function on our output layer - this function is used for categorical output. It turns the output into a probability distribution over the categories (i.e. it makes the values the network outputs sum to 1). So the network will essentially tell us how strongly it feels about each character being the next one.\n",
    "\n",
    "The categorical cross-entropy loss the standard loss function for multilabel classification.\n",
    "\n",
    "We use dropout here to prevent overfitting - we don't want the network to just return things already in the text, we want it to have some wiggle room and create novelty! Dropout is a technique where, in training, some percent (here, 20%) of random neurons of the associated layer are \"turned off\" for that epoch. This prevents overfitting but preventing the network from relying on particular neurons.\n",
    "\n",
    "That's it for the network architecture!\n",
    "\n",
    "To train, we have to do some additional preparation. We need to chop up the text into character sequences of the length we specified (`max_len`) - these are our training inputs. We match them with the character that immediately follows each sequence. These are our expected training outputs.\n",
    "\n",
    "For example, say we have the following text (this quote is from Zhuang Zi). With `max_len=20`, we could manually create the first couple training examples like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fish trap exists\n",
      " \n",
      " fish trap exists be\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "example = \"The fish trap exists because of the fish. Once you've gotten the fish you can forget the trap. The rabbit snare exists because of the rabbit. Once you've gotten the rabbit, you can forget the snare. Words exist because of meaning. Once you've gotten the meaning, you can forget the words. Where can I find a man who has forgotten words so that I may have a word with him?\"\n",
    "\n",
    "# step size here is 3, but we can vary that\n",
    "input_1 = example[0:20]\n",
    "true_output_1 = example[20]\n",
    "# >>> 'The fish trap exists'\n",
    "# >>> ' '\n",
    "\n",
    "print(input_1)\n",
    "print(true_output_1)\n",
    "\n",
    "input_2 = example[3:23]\n",
    "true_output_2 = example[23]\n",
    "# >>> 'fish trap exists be'\n",
    "# >>> 'c'\n",
    "\n",
    "print(input_2)\n",
    "print(true_output_2)\n",
    "\n",
    "input_3 = example[6:26]\n",
    "true_output_3 = example[26]\n",
    "# >>> 'sh trap exists becau'\n",
    "# >>> 's'\n",
    "\n",
    "# etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when the shoe fits, the foot is \n",
      "f\n"
     ]
    }
   ],
   "source": [
    "# We can generalize this like so:\n",
    "step = 3\n",
    "inputs = []\n",
    "outputs = []\n",
    "for i in range(0, len(text) - max_len, step):\n",
    "    inputs.append(text[i:i+max_len])\n",
    "    outputs.append(text[i+max_len])\n",
    "    \n",
    "print(inputs[0])\n",
    "print(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "# We also need to map each character to a label and create a reverse mapping to use later:\n",
    "char_labels = {ch:i for i, ch in enumerate(chars)}\n",
    "labels_char = {i:ch for i, ch in enumerate(chars)}\n",
    "\n",
    "# save these for later\n",
    "json.dump(char_labels, open('../data/char_labels.json', 'w'))\n",
    "json.dump(labels_char, open('../data/labels_char.json', 'w'))\n",
    "\n",
    "print(char_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start constructing our numerical input 3-tensor and output matrix. Each input example (i.e. a sequence of characters) is turned into a matrix of one-hot vectors; that is, a bunch of vectors where the index corresponding to the character is set to 1 and all the rest are set to zero.\n",
    "\n",
    "For example, if we have the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assuming max_len = 7\n",
    "# so our examples have 7 characters\n",
    "example = 'cab dab'\n",
    "example_char_labels = {\n",
    "    'a': 0,\n",
    "    'b': 1,\n",
    "    'c': 2,\n",
    "    'd': 3,\n",
    "    ' ' : 4\n",
    "}\n",
    "\n",
    "# matrix form\n",
    "# only five characters, so the vectors only need to have five components\n",
    "[\n",
    "    [0, 0, 1, 0, 0], # c\n",
    "    [1, 0, 0, 0, 0], # a\n",
    "    [0, 1, 0, 0, 0], # b\n",
    "    [0, 0, 0, 0, 1], # (space)\n",
    "    [0, 0, 0, 1, 0], # d\n",
    "    [1, 0, 0, 0, 0], # a\n",
    "    [0, 1, 0, 0, 0]  # b\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_to_matrix(text):\n",
    "    assert len(text) == max_len\n",
    "    X = np.zeros((1, max_len, len(chars)), dtype=np.bool)\n",
    "    for i, char in enumerate(text):\n",
    "        X[0, i, char_labels[char]] = 1\n",
    "    return X   \n",
    "    \n",
    "print(char_labels['t'])\n",
    "text_to_matrix('this here is an example text!!!!').astype(int)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That matrix represents a single training example, so we have a stack of those matrices (hence a 3-tensor). The outputs for each example are each a one-hot vector. With that in mind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using bool to reduce memory usage\n",
    "X = np.zeros((len(inputs), max_len, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(inputs), len(chars)), dtype=np.bool)\n",
    "\n",
    "# set the appropriate indices to 1| in each one-hot vector\n",
    "for i, example in enumerate(inputs):\n",
    "    for t, char in enumerate(example):\n",
    "        X[i, t, char_labels[char]] = 1\n",
    "    y[i, char_labels[outputs[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3c0789764f27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtext_to_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'abc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-3c0789764f27>\u001b[0m in \u001b[0;36mtext_to_matrix\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtext_to_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def text_to_matrix(text):\n",
    "    assert len(text) == max_len\n",
    "    X = np.zeros((1, max_len, len(chars)), dtype=np.bool)\n",
    "    for i, char in enumerate(text):\n",
    "        X[0, i, char_labels[char]] = 1\n",
    "    return X   \n",
    "    \n",
    "text_to_matrix('abc').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our training data, we can start training. Keras also makes this easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# more epochs is usually better, but training can be very slow if not on a GPU\n",
    "#epochs = 10\n",
    "#model.fit(X, y, batch_size=128, nb_epoch=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's much more fun to see your network's ramblings as it's training, so let's write a function to produce text from the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate(temperature=0.35, seed=None, predicate=lambda x: len(x) < 100):\n",
    "    if seed is not None and len(seed) < max_len:\n",
    "        raise Exception('Seed text must be at least {} chars long'.format(max_len))\n",
    "\n",
    "    # if no seed text is specified, randomly select a chunk of text\n",
    "    else:\n",
    "        start_idx = random.randint(0, len(text) - max_len - 1)\n",
    "        seed = text[start_idx:start_idx + max_len]\n",
    "\n",
    "    sentence = seed\n",
    "    generated = sentence\n",
    "\n",
    "    while predicate(generated):\n",
    "        # generate the input tensor\n",
    "        # from the last max_len characters generated so far\n",
    "        X = text_to_matrix(sentence)\n",
    "\n",
    "        # this produces a probability distribution over characters\n",
    "        probs = model.predict(X, verbose=0)[0]\n",
    "\n",
    "        # sample the character to use based on the predicted probabilities\n",
    "        next_idx = sample(probs, temperature)\n",
    "        next_char = labels_char[next_idx]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "    return generated\n",
    "\n",
    "def sample(probs, temperature):\n",
    "    \"\"\"samples an index from a vector of probabilities\"\"\"\n",
    "    a = np.log(probs)/temperature\n",
    "    a = np.exp(a)/np.sum(np.exp(a))\n",
    "    return np.argmax(np.random.multinomial(1, a, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temperature controls how random we want the network to be. Lower temperatures favors more likely values, whereas higher temperatures introduce more and more randomness. At a high enough temperature, values will be chosen at random.\n",
    "\n",
    "With this generation function we can modify how we train the network so that we see some output at each step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.load_weights('../data/rnn_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Epoch 1/1\n",
      "53743/53743 [==============================] - 60s - loss: 0.0257    \n",
      "\n",
      "\ttemperature: 0.2\n",
      "ursue.\n",
      "do not use a cannon to kike your own his sour is one who real, st that you may for right of w\n",
      "\n",
      "\ttemperature: 0.5\n",
      "hout conflicts, as if he never learning without soun tialing it to be flowe of for it.\n",
      "is the way is\n",
      "\n",
      "\ttemperature: 1.0\n",
      "ned attention rejects nothing not its achieved to the wise man do not mutur to governmy\n",
      "haspentading\n",
      "\n",
      "\ttemperature: 1.2\n",
      "asked for little; by these three s–ings without being since; their jundly his for a letlances are ev\n",
      "epoch 1\n",
      "Epoch 1/1\n",
      "53743/53743 [==============================] - 60s - loss: 0.0269    \n",
      "\n",
      "\ttemperature: 0.2\n",
      "nd curse at the man to steer clear. from the right way, the world can confide with the ver, will and\n",
      "\n",
      "\ttemperature: 0.5\n",
      "dness. one who really loves good posing them.\n",
      "a doysth peaperigh to med, if wo seet mind be somethen\n",
      "\n",
      "\ttemperature: 1.0\n",
      "ant it, catch the fish and you foulds his strong to atters which muth on compose gean is for a doy't\n",
      "\n",
      "\ttemperature: 1.2\n",
      "going forward, then i shall be moking it wish it is reother for others, and the thut me is not in he\n",
      "epoch 2\n",
      "Epoch 1/1\n",
      "53743/53743 [==============================] - 60s - loss: 0.0274    \n",
      "\n",
      "\ttemperature: 0.2\n",
      "sing the river of the world, no one who are somethe be obrect of water to stedvence concennes kill p\n",
      "\n",
      "\ttemperature: 0.5\n",
      "ts adversity and prosperity.\n",
      "the way of true genire the redorm.\n",
      "the chears the man a dives expect, b\n",
      "\n",
      "\ttemperature: 1.0\n",
      "s no difference as to his skil.\n",
      "if his ineres\n",
      "and dingress and his sourth for qoing the rull of endi\n",
      "\n",
      "\ttemperature: 1.2\n",
      "erous, you will gain everything.\n",
      "in a 1outh is not worth can it in when youn that you may come can i\n",
      "epoch 3\n",
      "Epoch 1/1\n",
      "53743/53743 [==============================] - 60s - loss: 0.0284    \n",
      "\n",
      "\ttemperature: 0.2\n",
      "gs with all the people, you can but retulnes fire the proper and uplose no forte. but it is not endi\n",
      "\n",
      "\ttemperature: 0.5\n",
      "as nothing to do with benevolence is of preaching about aqperings to be externed by others.\n",
      "bet entr\n",
      "\n",
      "\ttemperature: 1.0\n",
      "ute. what bitterness! he lives for adpints, but the thought of the wind be not exprose their loves o\n",
      "\n",
      "\ttemperature: 1.2\n",
      "ng pleasure in idle gadding about in.\n",
      "a grout is not what is meant, then stangition to the undormant\n",
      "epoch 4\n",
      "Epoch 1/1\n",
      "53743/53743 [==============================] - 60s - loss: 0.0289    \n",
      "\n",
      "\ttemperature: 0.2\n",
      "nd about in helpless confusion. when the factiteed to mell man tho fall is the proper does not forge\n",
      "\n",
      "\ttemperature: 0.5\n",
      "hing to do with benevolence and his endire arvisy and when you he as the does not in haspend, to be \n",
      "\n",
      "\ttemperature: 1.0\n",
      "in the sky from which the light of the unformented prochien, we can the people will see  undoot.\n",
      "the\n",
      "\n",
      "\ttemperature: 1.2\n",
      "posed; the lesser person is continueuty. the one foving to proper ming. when you make and chill-ts w\n",
      "epoch 5\n",
      "Epoch 1/1\n",
      "53743/53743 [==============================] - 60s - loss: 0.0259    \n",
      "\n",
      "\ttemperature: 0.2\n",
      "scover themselves. indeed one disfor uppint them.\n",
      "the perfect without the mind be mose it good post \n",
      "\n",
      "\ttemperature: 0.5\n",
      "f it.\n",
      "i want you to be everything has worlds\n",
      "and not wateo tank condict what his readant--encoppise \n",
      "\n",
      "\ttemperature: 1.0\n",
      "pects the world to adjust itself; the quiet of the suplrior for our injucitions cannot and from it w\n",
      "\n",
      "\ttemperature: 1.2\n",
      "im; when you see a bad man, examinaty are love in the paminess. if you to know the ding, and the mil\n",
      "epoch 6\n",
      "Epoch 1/1\n",
      "53743/53743 [==============================] - 60s - loss: 0.0280    \n",
      "\n",
      "\ttemperature: 0.2\n",
      "dy, and at thirty i knew where the stare and his skethelly one how do is not sturngerto and have nat\n",
      "\n",
      "\ttemperature: 0.5\n",
      "anguage is not correct, then what is seed is in he will because his difficult to seeve, in the one w\n",
      "\n",
      "\ttemperature: 1.0\n",
      "cies.\n",
      "if you know the point of but [arsh and do; and feeling of the others are deed are deversoness.\n",
      "\n",
      "\ttemperature: 1.2\n",
      "orm and you wear it out by points of ah1om, he seeks not worth 9noul.... the way is not hard as his \n",
      "epoch 7\n",
      "Epoch 1/1\n",
      "53743/53743 [==============================] - 60s - loss: 0.0260    \n",
      "\n",
      "\ttemperature: 0.2\n",
      "or man in dealing with the world it cannot de the ution the limited in curreed.\n",
      "when what as everyth\n",
      "\n",
      "\ttemperature: 0.5\n",
      " i, who tell you this, am also a worth.\n",
      "the whole fell without love of learning degenerates into uno\n",
      "\n",
      "\ttemperature: 1.0\n",
      "man who moves a mountain begins wy that men do not resognize your do bet endorment—ecy one who rustr\n",
      "\n",
      "\ttemperature: 1.2\n",
      "ourself, do not do to others.\n",
      "be ghows what is in he stows what is pirtuent, and the way become bort\n",
      "epoch 8\n",
      "Epoch 1/1\n",
      "53743/53743 [==============================] - 60s - loss: 0.0256    \n",
      "\n",
      "\ttemperature: 0.2\n",
      "s life; and who does not forget the rast as its breeds in wirdout.\n",
      "the regled and the more man shoot\n",
      "\n",
      "\ttemperature: 0.5\n",
      " to be worthy to be known.\n",
      "they dubbet the friendship does not strat that they way is the way the pa\n",
      "\n",
      "\ttemperature: 1.0\n",
      "ns.\n",
      "does heaven ever speak? the ditfout of forgot the right which to be not qo? in he rise, bor his \n",
      "\n",
      "\ttemperature: 1.2\n",
      "he universe, nor the nature of all character.\n",
      ". the “oble knowledge is unferiog.\n",
      "all people k– knowl\n",
      "epoch 9\n",
      "Epoch 1/1\n",
      "53743/53743 [==============================] - 60s - loss: 0.0280    \n",
      "\n",
      "\ttemperature: 0.2\n",
      "es and harps.\n",
      "the superior man does not snow what you do not know he wast the pith and right of what\n",
      "\n",
      "\ttemperature: 0.5\n",
      "an yourself in this regard.\n",
      "the rules of the sappine of exprise in quention? and pare to everything \n",
      "\n",
      "\ttemperature: 1.0\n",
      "fore he speaks.\n",
      "to know and not siection is to what is reoll, we enjaggr what is real tham; and not \n",
      "\n",
      "\ttemperature: 1.2\n",
      "turn your thoughts to becoming hil! but not skeknow, and the bbot of the suppreos ment, and chears c\n",
      "epoch 10\n",
      "Epoch 1/1\n",
      "53743/53743 [==============================] - 60s - loss: 0.0258    \n",
      "\n",
      "\ttemperature: 0.2\n",
      " of word; let thy walk be plain and live devertuming, and you will five a mind?elw, se i small wates\n",
      "\n",
      "\ttemperature: 0.5\n",
      "hout any admixture of revenge.\n",
      "sut leadnsing is learning for a llavising, and the bole for the patti\n",
      "\n",
      "\ttemperature: 1.0\n",
      "gories of thought. expression is the man tho full en of his ffor and his sare.\n",
      "if you know a prtan i\n",
      "\n",
      "\ttemperature: 1.2\n",
      " to confer a great office on a mas, pestice in whate the heart in seering the unferior of the dight \n",
      "epoch 11\n",
      "Epoch 1/1\n",
      "53743/53743 [==============================] - 60s - loss: 0.0252    \n",
      "\n",
      "\ttemperature: 0.2\n",
      "l polishing, but evil words once of haspeffy and in the poseess.\n",
      "the grould weel and worthy people c\n",
      "\n",
      "\ttemperature: 0.5\n",
      ". it is the same with regard to what is roon in the right of the unkirita-is all exilces and rifless\n",
      "\n",
      "\ttemperature: 1.0\n",
      "e of his appetites; when he is me; a coundress and some able to compent [. to be one who has for the\n",
      "\n",
      "\ttemperature: 1.2\n",
      "say what you know. when you don't sto' your own has folgowizged.\n",
      "the ding man the divisue wor'd be o\n",
      "epoch 12\n",
      "Epoch 1/1\n",
      "53743/53743 [==============================] - 60s - loss: 0.0243    \n",
      "\n",
      "\ttemperature: 0.2\n",
      "us nature, and maintains constanuly fornow it. the right way, the world is considertant of i propect\n",
      "\n",
      "\ttemperature: 0.5\n",
      "stillness, how much more the faction as your eligging with the ,re, man cannot be learning at in all\n",
      "\n",
      "\ttemperature: 1.0\n",
      "t something, to know that you are is not , how respectef the bong of learning degenerates into unopr\n",
      "\n",
      "\ttemperature: 1.2\n",
      "s music will furnish the answer.\n",
      "when the superior man his sares of his kingno-s and betore people t\n",
      "epoch 13\n",
      "Epoch 1/1\n",
      "53743/53743 [==============================] - 60s - loss: 0.0255    \n",
      "\n",
      "\ttemperature: 0.2\n",
      "justice to be of highest importances of goodness is one if he be emprete of for a peasent the family\n",
      "\n",
      "\ttemperature: 0.5\n",
      "ualities that entitle him to offing the mind.\n",
      "he who wisked, how has pertless right of the universe,\n",
      "\n",
      "\ttemperature: 1.0\n",
      "aring and is suffering from poversty from diedness and the boundly your mind be fexsed pertaning, th\n",
      "\n",
      "\ttemperature: 1.2\n",
      "is distant, he will find sorrow them live betore than when i dind e man those tho gat that langelfs \n",
      "epoch 14\n",
      "Epoch 1/1\n",
      "53743/53743 [==============================] - 60s - loss: 0.0258    \n",
      "\n",
      "\ttemperature: 0.2\n",
      "w fortunate i am.\n",
      "when there is a sin wind but whey is a sen an he paste..\n",
      "the same heaven so what h\n",
      "\n",
      "\ttemperature: 0.5\n",
      " longer overstepped the boundarily and the bule of ding, and you may seek not to dee? a uttor the mi\n",
      "\n",
      "\ttemperature: 1.0\n",
      ", and, abroad, respectful to his knows he is going the encare the right of the snorlow the cultivati\n",
      "\n",
      "\ttemperature: 1.2\n",
      "nd alone. he who practices it will make a sim. lead –o not qorred to fims. why way you wa6th, be goo\n",
      "epoch 15\n",
      "Epoch 1/1\n",
      "53743/53743 [==============================] - 60s - loss: 0.0241    \n",
      "\n",
      "\ttemperature: 0.2\n",
      "e of a petty man are upon others who forto others whilh the buring without being is neal that in min\n",
      "\n",
      "\ttemperature: 0.5\n",
      "s unsettle the heart until the ord?\n",
      "if the tao seeks to be one who owelss.\n",
      "the furght of the simpali\n",
      "\n",
      "\ttemperature: 1.0\n",
      "ed by the cherishing of benevolence, with his works and how to be as a ceestare byouth un equsant th\n",
      "\n",
      "\ttemperature: 1.2\n",
      " be laborious in their affairs.\n",
      "when you seeval forceque, the sulen of and cherish thoughj up lost b\n",
      "epoch 16\n",
      "Epoch 1/1\n",
      "53743/53743 [==============================] - 60s - loss: 0.0255    \n",
      "\n",
      "\ttemperature: 0.2\n",
      "mpletely unaware of anyone.\n",
      "when you know a thing, woods all man has nothing bree the beginn the nor\n",
      "\n",
      "\ttemperature: 0.5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-d35e44f376f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtemp\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n\\ttemperature:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-cf03a5c82a4b>\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(temperature, seed, predicate)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# this produces a probability distribution over characters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# sample the character to use based on the predicted probabilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ftseng/env/data/lib/python3.4/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m    454\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The model needs to be compiled before being used.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ftseng/env/data/lib/python3.4/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m   1117\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m         return self._predict_loop(f, ins,\n\u001b[1;32m-> 1119\u001b[1;33m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[0;32m   1120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m/home/ftseng/env/data/lib/python3.4/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[1;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[0;32m    837\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ftseng/env/data/lib/python3.4/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m         \u001b[0mupdated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ftseng/env/data/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munique_fetch_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ftseng/env/data/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m       return tf_session.TF_Run(self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 428\u001b[1;33m                                target_list)\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for i in range(epochs):\n",
    "    print('epoch', i)\n",
    "\n",
    "    # set nb_epoch to 1 since we're iterating manually\n",
    "    model.fit(X, y, batch_size=128, nb_epoch=1)\n",
    "\n",
    "    # preview\n",
    "    for temp in [0.2, 0.5, 1., 1.2]:\n",
    "        print('\\n\\ttemperature:', temp)\n",
    "        print(generate(temperature=temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.00001397e-06   2.80735876e-05   9.46933960e-06   5.43392207e-06\n",
      "   3.49110669e-05   1.70629039e-06   2.42977985e-05   7.48615048e-06\n",
      "   6.62929233e-05   9.18385995e-05   2.01816347e-05   2.62423346e-05\n",
      "   4.65566809e-05   6.38020574e-05   1.40279280e-05   6.79562254e-06\n",
      "   2.74334680e-02   4.72666397e-06   4.43568524e-06   5.33993580e-06\n",
      "   8.95277932e-02   2.80566983e-05   1.41700075e-05   9.82897291e-06\n",
      "   1.64385392e-06   7.50756415e-04   1.83898410e-05   4.32520574e-05\n",
      "   1.61204443e-05   1.30278338e-02   3.53071925e-07   2.15010077e-05\n",
      "   2.59341788e-03   5.52115016e-05   1.99425282e-04   7.56298065e-01\n",
      "   7.79547903e-04   6.98449984e-02   1.17372104e-03   3.52754751e-06\n",
      "   8.57619580e-06   1.09828979e-05   3.16713303e-02   2.83128011e-05\n",
      "   1.10223718e-05   1.35725877e-05   4.66116362e-05   6.51471464e-06\n",
      "   2.66835686e-05   3.04617934e-05   1.55112648e-05   1.31269935e-05\n",
      "   2.82209330e-05   2.70051096e-05   8.05384072e-04   6.99899920e-06\n",
      "   9.75621806e-05   4.82850382e-03   1.58866169e-05]\n"
     ]
    }
   ],
   "source": [
    "input = 'when the shoe fits, the foot is '\n",
    "X = text_to_matrix(input)\n",
    "probs = model.predict(X, verbose=0)[0]\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "idx = np.argmax(probs)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_char[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate(temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save these for later\n",
    "model.save_weights('../data/rnn_weights.h5', overwrite=True)\n",
    "json.dump(char_labels, open('../data/char_labels.json', 'w'))\n",
    "json.dump(labels_char, open('../data/labels_char.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
