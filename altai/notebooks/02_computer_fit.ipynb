{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finding a function with machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats=['svg']\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lib import make_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/fashion.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we will use scikit-learn's LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# note the double brackets for X -- this is necessary to get X in the right format/shape\n",
    "X = df[['Weight']]\n",
    "y = df['Size']\n",
    "\n",
    "# create the model and \"fit\" it to the data (i.e. find the parameters, m & b, for us)\n",
    "# we'll go into more detail how this works in a little bit.\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what value's for m and b did we learn?\n",
    "m = model.coef_[0]\n",
    "b = model.intercept_\n",
    "\n",
    "print('m', m)\n",
    "print('b', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our algorithm gave us m=1.8,b=50 back and thus we have learned the function:\n",
    "\n",
    "$$\n",
    "y = 1.804x + 50.095\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# what does this line look like?\n",
    "sns.regplot(df['Weight'], df['Size'], fit_reg=False)\n",
    "xs, ys = make_line(m, b)\n",
    "plt.plot(xs, ys)\n",
    "plt.legend(['learned function', 'data'], loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it looks pretty good - but how do we know if this is actually a better fit?\n",
    "\n",
    "can we quantify \"good-fittedness\"?\n",
    "\n",
    "\n",
    "# yes we can üëçüèΩ\n",
    "\n",
    "there are a lot of different ways, but the general idea is to quantify how \"wrong\" our guessed function (the \"hypothesis\") is\n",
    "\n",
    "we can look at each data point and see how far off it is from the line we guessed, e.g.\n",
    "\n",
    "![](assets/error.png)\n",
    "\n",
    "to figure out how wrong we are across _all_ the data points, we can just get the average (mean) of these errors.\n",
    "\n",
    "we might also want to penalize bigger errors more, so we could first square these errors. that way big errors become really big, and small errors stay small-ish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wrongness(m, b, xs, true_ys):\n",
    "    pred_ys = m * xs + b\n",
    "    error = true_ys - pred_ys\n",
    "    sq_error = error**2\n",
    "    return np.mean(sq_error)\n",
    "\n",
    "wrongness(m, b, df['Weight'], df['Size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these \"wrongness\" functions are known as _cost functions_ (sometimes you'll seem them called _objective functions_ or _loss functions_). there are many different kinds! the one we came up with is called _mean squared error_ (which is what we did, took the mean of the squared errors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scikit-learn has this built-in, you'll see it gives the same answer\n",
    "from sklearn import metrics\n",
    "y_pred = model.predict(X)\n",
    "metrics.mean_squared_error(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# roughly normalize to get a sense of relative error\n",
    "metrics.mean_squared_error(y_pred, y)/np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's see what the MSE is for other line guesses\n",
    "sns.regplot(df['Weight'], df['Size'], fit_reg=False)\n",
    "\n",
    "# =====================\n",
    "guess_m, guess_b = 2, 2\n",
    "# =====================\n",
    "\n",
    "xs, ys = make_line(guess_m, guess_b)\n",
    "plt.plot(xs, ys)\n",
    "plt.legend([], loc=2)\n",
    "plt.legend(['guessed function', 'data'], loc=2)\n",
    "\n",
    "pred_ys = guess_m * X + guess_b\n",
    "metrics.mean_squared_error(pred_ys, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the line the linear regression algorithm learned is a pretty good fit!\n",
    "\n",
    "in fact, he function I used to generate the data was:\n",
    "\n",
    "$$\n",
    "y = 1.8x + 50\n",
    "$$\n",
    "\n",
    "so it's very close.\n",
    "\n",
    "but it's error is still pretty far from 0. don't we want it to get as close to 0 as possible?\n",
    "\n",
    "#  ‚úãüèΩ hold on: not necessarily\n",
    "\n",
    "yes, you normally want to get your error as low as possible, but we're doing something incorrectly in this example.\n",
    "\n",
    "you should not evaluate a model's performance on the data used to train it - if you evaluate this way, the model may _overfit_, that is, start to capture the idiosyncracies of the training data, which may not reflect the more general process you are trying to describe (we want our function to _generalize_ to new data). the best practice is to set aside some of your data for validation and use that to evaluate your model.\n",
    "\n",
    "to bring it back to fashion, you want your pants to fit everyone at a certain weight pretty well. overfitting is where the pants fits one person really, really well, and is a terrible fit for everyone else.\n",
    "\n",
    "![](assets/overfitting.png)\n",
    "(from [the Shape of Data](https://shapeofdata.files.wordpress.com))\n",
    "\n",
    "(The opposite of overfitting is underfitting, depicted on the left)\n",
    "\n",
    "the typical practice here is to divide our data into a separate __training__ and __testing__ set - that way our testing set acts as \"new\" data the model has not yet seen and you can get a better sense of how it will do on new data.\n",
    "\n",
    "there are also more sophisticated ways of getting better estimates of generalizability, but we'll stick with this for now.\n",
    "\n",
    "let's split our data into 70% training, 30% testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# (set random state for the purposes of demonstration)\n",
    "train, test = train_test_split(df[['Weight', 'Size']], train_size=0.7, random_state=1000)\n",
    "X_train = train[['Weight']]\n",
    "y_train = train['Size']\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "X_test = test[['Weight']]\n",
    "y_test = test['Size']\n",
    "y_pred = model.predict(X_test)\n",
    "metrics.mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the error is higher now (it won't necessarily be, though). \n",
    " \n",
    " ---\n",
    "\n",
    "# so how the heck does the algorithm learn the parameters? ü§î\n",
    "\n",
    "how does the algorithm come up with good values of $m$ and $b$?\n",
    "\n",
    "we use the cost function from before!\n",
    "\n",
    "remember that this tells the algorithm how \"wrong\" it is with its current guesses for $m$ and $b$ on the training data.\n",
    "\n",
    "the algorithm iteratively tries different parameters (i.e. different guesses at the underlying function) until it can (approximately) minimize this error. That is, it tries to _optimize_ the parameters (thus the algorithms used for selecting these parameters are called \"optimization algorithms\").\n",
    "\n",
    "different optimization algorithms have different ways of picking new guesses. The most popular one is _gradient descent_, which looks for the direction in which the error is decreasing, and then takes a step in that direction. üóª\n",
    "\n",
    "If we were just finding $m$, this might look like:\n",
    "\n",
    "![](assets/gradient_descent.svg)\n",
    "\n",
    "If we're finding both $m$ and $b$, this might look like:\n",
    "\n",
    "![](assets/gradient_descent_3d.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wrongness_for_slope_guess(m):\n",
    "    return wrongness(m, b, X.values, y.values)\n",
    "\n",
    "ms = np.linspace(0,5,100)\n",
    "losses = []\n",
    "for m in ms:\n",
    "    losses.append(wrongness_for_slope_guess(m))\n",
    "plt.plot(ms, losses)\n",
    "plt.xlabel('$m$')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are other optimization methods such as genetic algorithms, particle swarm optimization, etc...\n",
    "\n",
    "but gradient descent is by far the most common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
