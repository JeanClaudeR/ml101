<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>nomadic</title>
    <link rel="stylesheet" type="text/css" href="/static/css/index.css">
    <link rel="stylesheet" type="text/css" href="/override.css">

</head>

<body>
    
    <style>
        html, body {
            padding: 0 1em;
            font-family: "Helvetica Neue", "Helvetica", "Arial", "sans-serif";
            font-size: 1.5em;
        }
        img {
            max-width: 100%;
            margin: 0 auto;
            display: block;
        }
        a, a:visited {
            color: #8765FB;
        }
        .slide {
            border-bottom: 1px solid #eee;
            max-width: 960px;
            margin: 0 auto;
        }
        .slide:last-child {
            border-bottom: none;
        }

        /* Vertically center */
        .slide-inner {
            position: relative;
            top: 50%;
            transform: translateY(-50%);
        }

        blockquote {
            margin: 0;
            padding: 0 2em;
            border-left: 6px solid #8765FB;
            color: #5D5D5D;
        }
        mark {
            background: #95FF8E;
        }
        pre {
            color: #8765FB;
            padding: 2em;
            font-size: 1.2em;
            background: #F5F5F5;
        }
    </style>

    <main role="main">
        <div class="note" id="note">
            <h1>ML101</h1>
<p>Francis Tseng (@frnsys)</p>
<hr />
<p>let's start setting up b/c it will probably take awhile ⏳</p>
<pre><code>git clone https://github.com/frnsys/ml101
cd ml101
pip install -r requirements.txt
jupyter notebook
</code></pre>
<hr />
<h2>what we'll cover today</h2>
<p>how to use:</p>
<ol>
<li><a href="http://scikit-learn.org/stable/"><code>scikit-learn</code></a> for supervised linear learning</li>
<li><a href="http://keras.io/"><code>keras</code></a> for neural networks</li>
<li><a href="http://pandas.pydata.org/"><code>pandas</code></a> for handling data</li>
<li><a href="http://matplotlib.org/"><code>matplotlib</code></a> and <a href="https://web.stanford.edu/~mwaskom/software/seaborn/"><code>seaborn</code></a> for visualizing data</li>
</ol>
<hr />
<h2>assumptions</h2>
<ul>
<li>you have some python 🐍 experience</li>
<li>you know a bit of high school 🏫 math</li>
</ul>
<hr />
<h2>What do you know about machine learning? 💬</h2>
<hr />
<p>ok, so what the heck is machine learning doing? what is it even for?</p>
<h2>💻🤔</h2>
<hr />
<h2>✨~modeling the world~✨</h2>
<hr />
<p>we can model phenomena, both natural and artificial, as mathematical functions</p>
<h1>y ⟶ <mathjax>$f(x)$</mathjax></h1>
<h1>💫 ⟶ <mathjax>$f(⚛)$</mathjax></h1>
<h1>💹 ⟶ <mathjax>$f(📰)$</mathjax></h1>
<h1>🎼 ⟶ <mathjax>$f(🎼)$</mathjax></h1>
<h1>🎼 ⟶ <mathjax>$f(🎼,😶)$</mathjax></h1>
<hr />
<p>how could we come up with such a function? 🤔</p>
<p>there are <em>infinitely</em> many of them</p>
<hr />
<p>we could go and observe a lot of things and then try to figure out some equation that matched what we observed.</p>
<h1>🌎👀</h1>
<hr />
<p>but that is a tedious process...</p>
<hr />
<p>ok, let's have computers do it for us then</p>
<h1>🤖</h1>
<hr />
<p>this is in essence what "machine learning" is:</p>
<h3><em>using computers to learn functions from observations (data)</em></h3>
<hr />
<p>once you learn your mystery function, there's so much you can do with it:</p>
<ul>
<li>predict things</li>
<li>automate things/make decisions</li>
<li>gain insight into a system</li>
<li>emulate a system</li>
</ul>
<hr />
<p>let's get more concrete</p>
<h1>🐄</h1>
<hr />
<p>let's say you're a farmer. you have a herd of cows.</p>
<p>🐄🐄🐄🐄</p>
<p>you want to estimate how heavy a cow will grow to be given its birth weight.</p>
<hr />
<p>you collect some data which looks like this:</p>
<p><img alt="" src="assets/ml101/cow_data.png" /></p>
<hr />
<p>we can try to learn a function that <em>fits</em> this data; i.e. that best describes (models) the relationship between the birth weight and mature weight.</p>
<hr />
<p>to better appreciate all the help computers give us, let's try this manually first.</p>
<hr />
<p><img alt="" src="assets/ml101/cow_data.png" /></p>
<p>this data looks like a line doesn't it?</p>
<hr />
<p>remember that a line can be described in the general form of</p>
<p><mathjax>$$
y = mx + b
$$</mathjax></p>
<hr />
<p>remember that lines vary depending on what the values of <mathjax>$m$</mathjax> and <mathjax>$b$</mathjax> are:</p>
<p><img alt="Lines" src="assets/ml101/lines.svg" /></p>
<p>we say that <mathjax>$m$</mathjax> and <mathjax>$b$</mathjax> <em>parameterize</em> the function (<mathjax>$m$</mathjax> and <mathjax>$b$</mathjax> are called "parameters").</p>
<hr />
<p>these parameters define a unique function, and thus when we "learn" a particular function, we are actually learning these parameters!</p>
<hr />
<p>if we wanted to learn these parameters manually, we could use the good old "guess-and-check" method:</p>
<p><img alt="" src="assets/ml101/cow_guess.png" /></p>
<hr />
<p>this was an easy dataset - real world data may be much more convoluted, not describable by a line, in many more dimensions, etc...manually figuring out the function gets kinda hard then.</p>
<p><img alt="" src="assets/ml101/nonconvex.svg" /></p>
<hr />
<p>(example in notebook 🗒)</p>
<hr />
<p>essentially every machine learning technique learns what these parameters are, and one of what differentiates algorithms is the approach with which they do this learning.</p>
<p>another main differentiator is what <em>kinds</em> of functions the algorithm can learn - some can only learn lines, while others can learn much fancier functions.</p>
<hr />
<h2>so how the heck does the algorithm learn the parameters?</h2>
<h1>🤔</h1>
<hr />
<p>it varies, but usually via a <em>cost</em> or <em>objective</em> function (often notated <mathjax>$J$</mathjax>).</p>
<p>this tells the algorithm how "wrong" it is with its current guesses for the parameters on the training data.</p>
<hr />
<p>the algorithm iteratively tries different parameters (i.e. different guesses at the underlying function) until it can minimize this error.</p>
<p>that is, it tries to <em>optimize</em> the parameters for the cost function.</p>
<hr />
<p>different optimization algorithms have different ways of picking new guesses.</p>
<p>the most popular one is <em>gradient descent</em>, which looks for the direction in which the error is decreasing, and then takes a step in that direction.</p>
<h1>🗻</h1>
<hr />
<p>if we were just finding <mathjax>$m$</mathjax>, this might look like:</p>
<p><img alt="" src="assets/ml101/gradient_descent.svg" /></p>
<hr />
<p>if we're finding both <mathjax>$m$</mathjax> and <mathjax>$b$</mathjax>, this might look like:</p>
<p><img alt="" src="assets/ml101/gradient_descent_3d.svg" /></p>
<hr />
<p>there are other optimization methods such as genetic algorithms, particle swarm optimization, etc...</p>
<p>but gradient descent is by far the most common.</p>
<hr />
<p>another example:</p>
<h1>the office of social health</h1>
<p><img alt="" src="assets/ml101/safety_in_numbers.sm.jpg" /></p>
<p>(based on the psycho-pass series)</p>
<hr />
<h2>ok, let's switch gears and talk about 🎉~neural networks~🎉</h2>
<p>they have many, many fun and interesting applications</p>
<hr />
<p>a neural network does essentially what we were doing before, but it can learn more sophisticated functions 💪🏽</p>
<hr />
<p><img alt="" src="assets/ml101/nn.png" /></p>
<h6>(from <a href="http://neuralnetworksanddeeplearning.com/">neuralnetworksanddeeplearning.com</a>)</h6>
<hr />
<p>one particularly fun kind of neural network is a <em>recurrent neural network</em></p>
<p><img alt="" src="assets/ml101/rnn.png" /></p>
<h6>(from <a href="http://www.hexahedria.com/2015/08/03/composing-music-with-recurrent-neural-networks/">hexahedria</a>)</h6>
<p>these are great for modeling <em>sequences</em>, e.g. text📝, music🎶, time series🕐, and so on</p>
<hr />
<p>there are examples abound here, such as generated texts in the style of <a href="https://www.countbayesie.com/blog/2015/5/24/writing-finnegans-wake-with-a-recurrent-neural-net">Finnegan's Wake</a>, endless new episode scripts for <a href="http://fullest.house/">Full House</a>, and algorithimically-composed <a href="https://medium.com/dbrs-innovation-labs/in-his-novel-galatea-2-2-e9d11c9b7c2a#.xd00cremz">sheet music</a>.</p>
<hr />
<p>sounds like a lot of fun, but there's one hangup...</p>
<h1>🙁</h1>
<hr />
<h2>what if the inputs we want to use aren't numbers? 🤔</h2>
<p>for example, how do you put a piece of text into a function?</p>
<h1>📖 ⟶ 🔢</h1>
<p>how do you <em>represent</em> it as a number?</p>
<hr />
<p>this is the problem of <em>representation</em>, and it is key to machine learning.</p>
<p>coming up with good representations is called <em>feature engineering</em> and it can be more of an art than a skill.</p>
<h1>🛠 + 🎨</h1>
<hr />
<p>for text, one option is to map each word to a unique number.</p>
<h1>🙃</h1>
<hr />
<p>(example in notebook 🗒)</p>
<hr />
<p>one last kind of machine learning that I really enjoy:</p>
<h2>reinforcement learning</h2>
<h1>🐶</h1>
<hr />
<p>what we've seen so far is pretty cool, but things <em>really</em> get fun when we start designing agents that can act independently;</p>
<p>where they can interact with an environment on their own, learn from it, and develop new behaviors 🤖</p>
<hr />
<p>reinforcement learning is behind neat stuff like Google DeepMind's <em>AlphaGo</em> 🏆 and their <a href="https://www.youtube.com/watch?v=Vr5MR5lKOc8">Atari-playing AIs</a> 🕹</p>
<hr />
<p>the behavior of the agent can be described by (you guessed it) a function, and of course we want to learn it 🎓</p>
<hr />
<p>the basic idea:</p>
<ul>
<li>we model the world as various <em>states</em> 🙍🏽 the agent can be in.</li>
<li>the agent can take <em>actions</em> 🏧 that move between these states.</li>
<li>each state has an associated <em>reward</em> 💰 (or punishment 🗡).</li>
<li>the agent <em>explores</em> 🗺 these states and learns which sequence of actions tend to lead to more rewards.</li>
</ul>
<p>this is given to us by a function, usually called <mathjax>$q$</mathjax>, which, given a state, maps actions to values - so this is the function we want to learn.</p>
<hr />
<p><img alt="" src="assets/ml101/mdp.png" /></p>
<p>a very simple set of agent states and actions. this agent will eventually spend all of its time sleeping 💤.</p>
<hr />
<p>a very simple environment for a RL agent is a "grid world"</p>
<p><img alt="" src="assets/ml101/mdp_grid.png" /></p>
<hr />
<p><img alt="" src="assets/ml101/workshop_rl.gif" /></p>
<p>(example in notebook 🗒)</p>
<hr />
<p>through this process you've seen how much decision making we as people had to make with regards to what goes into the algorithm, which one we use, and so on.</p>
<h1>🤔</h1>
<p>hopefully it is clear that machine learning can't be claimed to be "fully objective" 🚽 or anything of the sort</p>
<hr />
<p>thanks!</p>
<p>if you want to go deeper: <a href="http://frnsys.com/ai_notes/">frnsys.com/ai_notes/</a></p>
<p>~ @frnsys</p>
        </div>
        <div id="presentation">
        </div>
    </main>

    <script type="text/javascript">
        var nodes = document.getElementById('note').childNodes,
            out = document.getElementById('presentation'),
            els = [[]];

        function build_slide(elms) {
            var slide = document.createElement('div'),
                inner = document.createElement('div');

            slide.className = 'slide';
            inner.className = 'slide-inner';

            for(var j=0; j<elms.length; j++) {
                inner.appendChild(elms[j]);
            }
            slide.appendChild(inner);
            out.appendChild(slide);
        }

        function resize_slides() {
            var slides = document.getElementsByClassName('slide'),
                win_height = window.innerHeight;
            for (var i=0; i<slides.length; i++) {
                var slide_height = slides[i].clientHeight;
                if (slide_height > win_height) {
                    var scale = win_height/slide_height,
                        transform = 'scale(' + scale + ')';
                    slides[i].style.webkitTransform = transform;
                    slides[i].style.mozTransform    = transform;
                    slides[i].style.transform       = transform;
                }
                slides[i].style.height = win_height + "px";
            }
        }
        window.onresize = resize_slides();

        // Build slides out of the note html, interpreting `hr` as a slide break.
        for (var i=0; i<nodes.length; i++) {
            if (nodes[i].nodeName.toLowerCase() == 'hr') {
                els.push([]);
            } else {
                els[els.length - 1].push(nodes[i]);
            }
        }
        for (var i=0; i<els.length; i++) {
            build_slide(els[i]);
        }
        document.getElementById('note').style.display = 'none';
        resize_slides();

        // Key navigation.
        document.onkeydown = function(e) {
            var slides = document.getElementsByClassName('slide'),
                curr_slide;
            for (var i=0; i<slides.length; i++) {
                var y   = window.pageYOffset,
                    wh  = window.outerHeight,
                    h   = slides[i].offsetHeight,
                    top = slides[i].offsetTop;
                if (top + h >= y + wh/2 && top + h <= y + wh ||
                    top <= y + wh/2 && top > y) {
                    curr_slide = i;
                    break;
                }
            }

            e = e || window.event;
            switch(e.which || e.keyCode) {
                case 40: // down
                    if (i < slides.length - 1)
                        window.scrollTo(0, slides[i+1].offsetTop);
                    e.preventDefault();
                    break;
                case 38: // up
                    if (i > 0)
                        window.scrollTo(0, slides[i-1].offsetTop);
                    e.preventDefault();
                    break;
            }
        }
    </script>

    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script>
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [["$","$"]],
                displayMath: [['$$','$$']],
                processEscapes: true
            }
        });
        MathJax.Hub.Startup.onload();
    </script>

</body>
</html>